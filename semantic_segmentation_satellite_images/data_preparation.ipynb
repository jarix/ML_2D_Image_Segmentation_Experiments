{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f82104c",
   "metadata": {},
   "source": [
    "# Data Preparation Script\n",
    "\n",
    "* Download Kaggle Semantic Segmentation of aerial imagenary dataset from https://www.kaggle.com/datasets/humansintheloop/semantic-segmentation-of-aerial-imagery<br />\n",
    "* unzip to 'dataset/' folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0634dd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prequisites\n",
    "import os\n",
    "import re       # for regex operations\n",
    "from pathlib import Path  # for handling file paths\n",
    "import numpy as np\n",
    "from patchify import patchify  # for creating patches from images\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025032e2",
   "metadata": {},
   "source": [
    "### Check in running in Colab or Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aed26898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in Colab: False\n"
     ]
    }
   ],
   "source": [
    "# Check if notebook being run in Colab or locally  \n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "print (f'Running in Colab: {IN_COLAB}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782f9157",
   "metadata": {},
   "source": [
    "### Download Raw Data from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93ca06d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\Jari\\.cache\\kagglehub\\datasets\\humansintheloop\\semantic-segmentation-of-aerial-imagery\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "if IN_COLAB:\n",
    "    pass\n",
    "\n",
    "else: \n",
    "    # Download latest version\n",
    "    raw_data_path = kagglehub.dataset_download(\"humansintheloop/semantic-segmentation-of-aerial-imagery\")\n",
    "\n",
    "print(\"Path to dataset files:\", raw_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb5e68b",
   "metadata": {},
   "source": [
    "### Copy Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd1ef77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "src_dir = raw_data_path\n",
    "dst_dir = \"data/raw\"\n",
    "\n",
    "shutil.copytree(src_dir, dst_dir, dirs_exist_ok=True)\n",
    "\n",
    "# Delete temporary download directory\n",
    "shutil.rmtree(raw_data_path, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235736be",
   "metadata": {},
   "source": [
    "### Create Folders 'train', 'val', 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11b75985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folders(root_dir='.'):\n",
    "    FOLDER_NAMES = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "    for folder_name in FOLDER_NAMES:\n",
    "        if not os.path.exists(folder_name):\n",
    "            folder_images = f\"{root_dir}/{folder_name}/images\"\n",
    "            folder_masks = f\"{root_dir}/{folder_name}/masks\"\n",
    "            os.makedirs(folder_images) if not os.path.exists(folder_images) else print('images folder already exists')\n",
    "            os.makedirs(folder_masks) if not os.path.exists(folder_masks) else print('masks folder already exists')\n",
    "\n",
    "if IN_COLAB:\n",
    "    create_folders()\n",
    "else:\n",
    "    create_folders(\"data/processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8210c73",
   "metadata": {},
   "source": [
    "### Create Image Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7c87b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_patches(src, dest_path):\n",
    "    path_split = os.path.split(src)   # get the last part of the path\n",
    "    tile_num = re.findall(r'\\d+', path_split[0])[0]  # extract tile number using regex\n",
    "    \n",
    "    image = Image.open(src)   \n",
    "    image = np.asarray(image)  # convert to numpy array\n",
    "    if len(image.shape) > 2:  # need color channels\n",
    "        patches = patchify(image, (320, 320, 3), step=300)  # create patches of size 320x320 with overlap of 20 pixels\n",
    "        file_name_wo_ext = Path(src).stem   # get file name without extension\n",
    "        for i in range(patches.shape[0]): \n",
    "            for j in range(patches.shape[1]):\n",
    "                patch = patches[i, j, 0]\n",
    "                patch = Image.fromarray(patch)  # convert back to image\n",
    "                num = i * patches.shape[1] + j\n",
    "                patch.save(f\"{dest_path}/{file_name_wo_ext}_tile_{tile_num}_patch_{num}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b150a145",
   "metadata": {},
   "source": [
    "### Copy the files from dataset to 'train', 'val', and 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "016b98ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes.json\n",
      "image_part_001.jpg\n",
      "image_part_002.jpg\n",
      "image_part_003.jpg\n",
      "image_part_004.jpg\n",
      "image_part_005.jpg\n",
      "image_part_006.jpg\n",
      "image_part_007.jpg\n",
      "image_part_008.jpg\n",
      "image_part_009.jpg\n",
      "image_part_001.png\n",
      "image_part_002.png\n",
      "image_part_003.png\n",
      "image_part_004.png\n",
      "image_part_005.png\n",
      "image_part_006.png\n",
      "image_part_007.png\n",
      "image_part_008.png\n",
      "image_part_009.png\n",
      "image_part_001.jpg\n",
      "image_part_002.jpg\n",
      "image_part_003.jpg\n",
      "image_part_004.jpg\n",
      "image_part_005.jpg\n",
      "image_part_006.jpg\n",
      "image_part_007.jpg\n",
      "image_part_008.jpg\n",
      "image_part_009.jpg\n",
      "image_part_001.png\n",
      "image_part_002.png\n",
      "image_part_003.png\n",
      "image_part_004.png\n",
      "image_part_005.png\n",
      "image_part_006.png\n",
      "image_part_007.png\n",
      "image_part_008.png\n",
      "image_part_009.png\n",
      "image_part_001.jpg\n",
      "image_part_002.jpg\n",
      "image_part_003.jpg\n",
      "image_part_004.jpg\n",
      "image_part_005.jpg\n",
      "image_part_006.jpg\n",
      "image_part_007.jpg\n",
      "image_part_008.jpg\n",
      "image_part_009.jpg\n",
      "image_part_001.png\n",
      "image_part_002.png\n",
      "image_part_003.png\n",
      "image_part_004.png\n",
      "image_part_005.png\n",
      "image_part_006.png\n",
      "image_part_007.png\n",
      "image_part_008.png\n",
      "image_part_009.png\n",
      "image_part_001.jpg\n",
      "image_part_002.jpg\n",
      "image_part_003.jpg\n",
      "image_part_004.jpg\n",
      "image_part_005.jpg\n",
      "image_part_006.jpg\n",
      "image_part_007.jpg\n",
      "image_part_008.jpg\n",
      "image_part_009.jpg\n",
      "image_part_001.png\n",
      "image_part_002.png\n",
      "image_part_003.png\n",
      "image_part_004.png\n",
      "image_part_005.png\n",
      "image_part_006.png\n",
      "image_part_007.png\n",
      "image_part_008.png\n",
      "image_part_009.png\n",
      "image_part_001.jpg\n",
      "image_part_002.jpg\n",
      "image_part_003.jpg\n",
      "image_part_004.jpg\n",
      "image_part_005.jpg\n",
      "image_part_006.jpg\n",
      "image_part_007.jpg\n",
      "image_part_008.jpg\n",
      "image_part_009.jpg\n",
      "image_part_001.png\n",
      "image_part_002.png\n",
      "image_part_003.png\n",
      "image_part_004.png\n",
      "image_part_005.png\n",
      "image_part_006.png\n",
      "image_part_007.png\n",
      "image_part_008.png\n",
      "image_part_009.png\n",
      "image_part_001.jpg\n",
      "image_part_002.jpg\n",
      "image_part_003.jpg\n",
      "image_part_004.jpg\n",
      "image_part_005.jpg\n",
      "image_part_006.jpg\n",
      "image_part_007.jpg\n",
      "image_part_008.jpg\n",
      "image_part_009.jpg\n",
      "image_part_001.png\n",
      "image_part_002.png\n",
      "image_part_003.png\n",
      "image_part_004.png\n",
      "image_part_005.png\n",
      "image_part_006.png\n",
      "image_part_007.png\n",
      "image_part_008.png\n",
      "image_part_009.png\n",
      "image_part_001.jpg\n",
      "image_part_002.jpg\n",
      "image_part_003.jpg\n",
      "image_part_004.jpg\n",
      "image_part_005.jpg\n",
      "image_part_006.jpg\n",
      "image_part_007.jpg\n",
      "image_part_008.jpg\n",
      "image_part_009.jpg\n",
      "image_part_001.png\n",
      "image_part_002.png\n",
      "image_part_003.png\n",
      "image_part_004.png\n",
      "image_part_005.png\n",
      "image_part_006.png\n",
      "image_part_007.png\n",
      "image_part_008.png\n",
      "image_part_009.png\n",
      "image_part_001.jpg\n",
      "image_part_002.jpg\n",
      "image_part_003.jpg\n",
      "image_part_004.jpg\n",
      "image_part_005.jpg\n",
      "image_part_006.jpg\n",
      "image_part_007.jpg\n",
      "image_part_008.jpg\n",
      "image_part_009.jpg\n",
      "image_part_001.png\n",
      "image_part_002.png\n",
      "image_part_003.png\n",
      "image_part_004.png\n",
      "image_part_005.png\n",
      "image_part_006.png\n",
      "image_part_007.png\n",
      "image_part_008.png\n",
      "image_part_009.png\n"
     ]
    }
   ],
   "source": [
    "raw_data_root = \"data/raw/Semantic segmentation dataset\"\n",
    "processed_data_root = \"data/processed\"\n",
    "\n",
    "for path_name, _, file_name in os.walk(raw_data_root): # walk through all files and folders in dataset folder\n",
    "    for f in file_name:\n",
    "        print(f)\n",
    "        if f != 'classes.json':    # Do not process classes.json file\n",
    "            \n",
    "            path_split = os.path.split(path_name)  # get the last part of the path\n",
    "            tile_num = re.findall(r'\\d+', path_split[0])[0]\n",
    "            \n",
    "            img_type =path_split[1]  # either 'masks' or 'images'\n",
    "            \n",
    "            # Skip tile 2, it has issues with color dim\n",
    "            if tile_num in ['4', '5', '6', '7', '8']:\n",
    "                target_folder_imgs = f\"{processed_data_root}/train\"\n",
    "                target_folder_masks = f\"{processed_data_root}/train\"\n",
    "            elif tile_num == '3':\n",
    "                target_folder_imgs = f\"{processed_data_root}/val\"\n",
    "                target_folder_masks = f\"{processed_data_root}/val\"\n",
    "            elif tile_num == '1':\n",
    "                target_folder_imgs = f\"{processed_data_root}/test\"\n",
    "                target_folder_masks = f\"{processed_data_root}/test\"\n",
    "\n",
    "            # copy all images\n",
    "            src = os.path.join(path_name, f)  \n",
    "            file_name_wo_ext = Path(src).stem  # get file name without extension\n",
    "            # check if file exists in images and masks\n",
    "            img_file = f\"{path_split[0]}/images/{file_name_wo_ext}.jpg\"  # image files are .jpg\n",
    "            mask_file = f\"{path_split[0]}/masks/{file_name_wo_ext}.png\"  # mask files are .png\n",
    "            if os.path.exists(img_file) and os.path.exists(mask_file):\n",
    "                if img_type == 'images':\n",
    "                    dest = os.path.join(target_folder_imgs, img_type)\n",
    "                    create_patches(src=src, dest_path=dest)\n",
    "                    \n",
    "                # copy all masks\n",
    "                if img_type == 'masks':\n",
    "                    dest = os.path.join(target_folder_masks, img_type)\n",
    "                    create_patches(src=src, dest_path=dest)\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
